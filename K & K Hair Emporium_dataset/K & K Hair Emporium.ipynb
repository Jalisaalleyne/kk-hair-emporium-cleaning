{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ef14e9",
   "metadata": {},
   "source": [
    "## Phase 1: Setup and Inspection of Raw Data\n",
    "\n",
    "### Step 1: Import Required Libraries\n",
    "Import all necessary packages for data processing, logging, and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f10cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path          # file/folder paths (works on Windows/macOS)\n",
    "import pandas as pd               # data loading + cleaning\n",
    "import logging                    # run log (what happened + when)\n",
    "import re                         # pattern matching and string manipulation\n",
    "import unicodedata                # Unicode character properties and normalization\n",
    "import sys                        # system-specific parameters and functions\n",
    "import glob                       # file path pattern matching and expansion\n",
    "import numpy as np                # numerical computing and array operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e069b",
   "metadata": {},
   "source": [
    "### Step 2: Setup Project Folder Structure\n",
    "Configure paths and create all required directories for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700eda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Project root (K & K Hair Emporium folder)\n",
    "# ===============================\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "# ===============================\n",
    "# Logs setup (MUST come first)\n",
    "# ===============================\n",
    "LOGS_DIR = ROOT / \"K & K Hair Emporium_logs\"\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_FILE = LOGS_DIR / \"setup.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Starting folder setup process.\")\n",
    "\n",
    "# ===============================\n",
    "# Dataset base folder\n",
    "# ===============================\n",
    "DATASET_DIR = ROOT / \"K & K Hair Emporium_dataset\"\n",
    "K_AND_K_RAW_DIR = DATASET_DIR / \"k & k hair emporium_raw\"\n",
    "\n",
    "# ===============================\n",
    "# Subfolders\n",
    "# ===============================\n",
    "RAW_DIR = K_AND_K_RAW_DIR / \"k & k hair emporium_raw\"\n",
    "PROCESSED_DIR = K_AND_K_RAW_DIR / \"k & k hair emporium_processed\"\n",
    "GARBAGE_DIR = K_AND_K_RAW_DIR / \"k & k hair emporium_garbage\"\n",
    "INGESTED_DIR = K_AND_K_RAW_DIR / \"k & k hair emporium_ingested\"\n",
    "\n",
    "# ===============================\n",
    "# Folder creation function\n",
    "# ===============================\n",
    "def create_folders():\n",
    "    folders = [\n",
    "        RAW_DIR,\n",
    "        PROCESSED_DIR,\n",
    "        GARBAGE_DIR,\n",
    "        INGESTED_DIR,\n",
    "        LOGS_DIR,\n",
    "    ]\n",
    "\n",
    "    for folder in folders:\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "        logging.info(f\"Ensured folder exists: {folder}\")\n",
    "\n",
    "# ===============================\n",
    "# Create the folders\n",
    "# ===============================\n",
    "create_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd67cd3",
   "metadata": {},
   "source": [
    "### Step 3: Inspect the Raw K & K Hair Emporium CSV\n",
    "Load and preview the unprocessed raw data file for initial inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa89a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV file found: \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_raw\\K & K  Emporium_raw.csv\n",
      "  File size: 188,373 bytes\n",
      "\n",
      "Shape: 1000 rows × 15 columns\n",
      "\n",
      "Columns:\n",
      "['  Name  nsuef', 'Email Addresshbjjb ', ' Password 12582', 'Salt %^bh ', 'Date of Birth   ', 'Street Name  9x9x ', 'Parish   hbjjb', ' Zip   12582', 'Country  %^bh', 'Account Branch   ', 'Loyalty Pointsnsuef ', 'Gender  ', 'Contact Number  (raw) ', 'Signup Date 2018 ', 'Total Purchases  ']\n",
      "\n",
      "First 5 rows:\n",
      "        Name  nsuef                    Email Addresshbjjb     Password 12582  \\\n",
      "0  Shanice O'Connor     Shanice.OConnor@KKHAIREMPORIUM.COM            BD#dz*   \n",
      "1       Renée Lewis               RENE.LEWIS@kandk-hair.co  CPhDeOZIiBOB@Y6s   \n",
      "2    Rohan Williams      Rohan.Williams@kkhairemporium.com            UNEhEk   \n",
      "3    Devon Baptiste  Devon.Baptiste.442@loyalty.kkhair.com            mhZRnF   \n",
      "4    Devon Baptiste      Devon.Baptiste@KKHAIREMPORIUM.COM            EZpFfk   \n",
      "\n",
      "         Salt %^bh  Date of Birth    Street Name  9x9x         Parish   hbjjb  \\\n",
      "0  e805da846a32c3bb       1958/11/24  Market Street #64            St. Thomas   \n",
      "1  78dcb74f21345d2c       1996/12/28   Market Street #6             Clarendon   \n",
      "2  f244f58d669cbee3      1960/09/29    Coral Ridge #284  St. Peter Basseterre   \n",
      "3  e4d58e72e310275d       1974/03/06     Bay Street #31  St. Peter Basseterre   \n",
      "4  a86a78c49ea20e32        2000/5/20    Bay Street #179           St. Michael   \n",
      "\n",
      "   Zip   12582      Country  %^bh Account Branch     Loyalty Pointsnsuef   \\\n",
      "0      BB23026           Barbados           Oistins               20267.0   \n",
      "1        99353            Jamaica      Spanish Town               11146.0   \n",
      "2       KN0101  St. Kitts & Nevis        Basseterre               23194.0   \n",
      "3       KN0101  St. Kitts & Nevis       Sandy Point                8690.0   \n",
      "4      BB23026           Barbados           Warrens                5169.0   \n",
      "\n",
      "            Gender   Contact Number  (raw)  Signup Date 2018   \\\n",
      "0         Non-binary            31034131647        2018/01/17   \n",
      "1             Female           + 62704828          2017-09-03   \n",
      "2             Female                1051834        2017/03/14   \n",
      "3  Prefer not to say            (687) 23430        2016-05-04   \n",
      "4  Prefer not to say       8498084124118244        2017/12/03   \n",
      "\n",
      "   Total Purchases    \n",
      "0               45.0  \n",
      "1               64.0  \n",
      "2               92.0  \n",
      "3                7.0  \n",
      "4               81.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the raw CSV for inspection\n",
    "CSV_FILE = RAW_DIR / \"K & K  Emporium_raw.csv\"\n",
    "\n",
    "if CSV_FILE.exists():\n",
    "    print(f\"✓ CSV file found: {CSV_FILE}\")\n",
    "    print(f\"  File size: {CSV_FILE.stat().st_size:,} bytes\")\n",
    "else:\n",
    "    print(f\"✗ ERROR: CSV file not found at {CSV_FILE}\")\n",
    "    raise FileNotFoundError(f\"Missing file: {CSV_FILE}\")\n",
    "\n",
    "# Load data\n",
    "df_raw = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\nShape: {df_raw.shape[0]} rows × {df_raw.shape[1]} columns\")\n",
    "print(\"\\nColumns:\")\n",
    "print(df_raw.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70188432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COLUMNS BY INDEX:\n",
      "--------------------------------------------------------------------------------\n",
      "[0]   Name  nsuef\n",
      "[1] Email Addresshbjjb \n",
      "[2]  Password 12582\n",
      "[3] Salt %^bh \n",
      "[4] Date of Birth   \n",
      "[5] Street Name  9x9x \n",
      "[6] Parish   hbjjb\n",
      "[7]  Zip   12582\n",
      "[8] Country  %^bh\n",
      "[9] Account Branch   \n",
      "[10] Loyalty Pointsnsuef \n",
      "[11] Gender  \n",
      "[12] Contact Number  (raw) \n",
      "[13] Signup Date 2018 \n",
      "[14] Total Purchases  \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Display Columns with Indexes\n",
    "# ===============================\n",
    "\n",
    "print(\"\\nCOLUMNS BY INDEX:\")\n",
    "print(\"-\" * 80)\n",
    "for idx, col in enumerate(df_raw.columns):\n",
    "    print(f\"[{idx}] {col}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208662d",
   "metadata": {},
   "source": [
    "## Phase 2: Data Cleaning and Column Selection\n",
    "\n",
    "### Step 5: Drop Unnecessary Columns\n",
    "Keep only the essential columns (indexes 0, 1, 3, 4) and move dropped columns to garbage folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b82d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COLUMN SELECTION\n",
      "================================================================================\n",
      "\n",
      "KEEPING 4 columns:\n",
      "  [0]   Name  nsuef\n",
      "  [1] Email Addresshbjjb \n",
      "  [3] Salt %^bh \n",
      "  [4] Date of Birth   \n",
      "\n",
      "DROPPING 11 columns to GARBAGE:\n",
      "  [2]  Password 12582\n",
      "  [5] Street Name  9x9x \n",
      "  [6] Parish   hbjjb\n",
      "  [7]  Zip   12582\n",
      "  [8] Country  %^bh\n",
      "  [9] Account Branch   \n",
      "  [10] Loyalty Pointsnsuef \n",
      "  [11] Gender  \n",
      "  [12] Contact Number  (raw) \n",
      "  [13] Signup Date 2018 \n",
      "  [14] Total Purchases  \n",
      "\n",
      "✓ Dropped columns saved to: \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_garbage\\dropped_columns.csv\n",
      "✓ Cleaned data saved to: \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_ingested\\df_cleaned.csv\n",
      "\n",
      "================================================================================\n",
      "CLEANED DATA SHAPE: 1000 rows × 4 columns\n",
      "================================================================================\n",
      "\n",
      "Cleaned data preview:\n",
      "        Name  nsuef                    Email Addresshbjjb         Salt %^bh   \\\n",
      "0  Shanice O'Connor     Shanice.OConnor@KKHAIREMPORIUM.COM  e805da846a32c3bb   \n",
      "1       Renée Lewis               RENE.LEWIS@kandk-hair.co  78dcb74f21345d2c   \n",
      "2    Rohan Williams      Rohan.Williams@kkhairemporium.com  f244f58d669cbee3   \n",
      "3    Devon Baptiste  Devon.Baptiste.442@loyalty.kkhair.com  e4d58e72e310275d   \n",
      "4    Devon Baptiste      Devon.Baptiste@KKHAIREMPORIUM.COM  a86a78c49ea20e32   \n",
      "\n",
      "  Date of Birth     \n",
      "0       1958/11/24  \n",
      "1       1996/12/28  \n",
      "2      1960/09/29   \n",
      "3       1974/03/06  \n",
      "4        2000/5/20  \n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Define columns to keep and drop\n",
    "# ===============================\n",
    "KEEP_INDEXES = [0, 1, 3, 4]\n",
    "ALL_INDEXES = list(range(len(df_raw.columns)))\n",
    "DROP_INDEXES = [idx for idx in ALL_INDEXES if idx not in KEEP_INDEXES]\n",
    "\n",
    "# Get column names\n",
    "KEEP_COLUMNS = [df_raw.columns[idx] for idx in KEEP_INDEXES]\n",
    "DROP_COLUMNS = [df_raw.columns[idx] for idx in DROP_INDEXES]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COLUMN SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nKEEPING {len(KEEP_COLUMNS)} columns:\")\n",
    "for idx, col in zip(KEEP_INDEXES, KEEP_COLUMNS):\n",
    "    print(f\"  [{idx}] {col}\")\n",
    "\n",
    "print(f\"\\nDROPPING {len(DROP_COLUMNS)} columns to GARBAGE:\")\n",
    "for idx, col in zip(DROP_INDEXES, DROP_COLUMNS):\n",
    "    print(f\"  [{idx}] {col}\")\n",
    "\n",
    "# ===============================\n",
    "# Create cleaned and garbage dataframes\n",
    "# ===============================\n",
    "df_cleaned = df_raw[KEEP_COLUMNS].copy()\n",
    "df_garbage = df_raw[DROP_COLUMNS].copy()\n",
    "\n",
    "# Add index column to garbage dataframe for reference\n",
    "df_garbage.insert(0, 'original_index', range(len(df_garbage)))\n",
    "\n",
    "# ===============================\n",
    "# Save garbage columns\n",
    "# ===============================\n",
    "GARBAGE_FILE = GARBAGE_DIR / \"dropped_columns.csv\"\n",
    "df_garbage.to_csv(GARBAGE_FILE, index=False)\n",
    "print(f\"\\n✓ Dropped columns saved to: {GARBAGE_FILE}\")\n",
    "\n",
    "# ===============================\n",
    "# Save cleaned data\n",
    "# ===============================\n",
    "INGESTED_FILE = INGESTED_DIR / \"df_cleaned.csv\"\n",
    "df_cleaned.to_csv(INGESTED_FILE, index=False)\n",
    "print(f\"✓ Cleaned data saved to: {INGESTED_FILE}\")\n",
    "\n",
    "# Log the operation\n",
    "logging.info(f\"Dropped {len(DROP_COLUMNS)} columns and kept {len(KEEP_COLUMNS)} columns\")\n",
    "logging.info(f\"Garbage columns saved to {GARBAGE_FILE}\")\n",
    "logging.info(f\"Cleaned data saved to {INGESTED_FILE}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"CLEANED DATA SHAPE: {df_cleaned.shape[0]} rows × {df_cleaned.shape[1]} columns\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nCleaned data preview:\")\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ee42f",
   "metadata": {},
   "source": [
    "# Ensure column names match expected list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab56d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Old column names written to \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_garbage\\old_column_names.csv\n",
      "Renamed cleaned dataframe columns to expected names:\n",
      "['Name', 'Email Address', 'Salt', 'Date of Birth']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPECTED_COLS = [\"Name\", \"Email Address\", \"Salt\", \"Date of Birth\"]\n",
    "old_columns = df_cleaned.columns.tolist()\n",
    "if len(old_columns) == len(EXPECTED_COLS):\n",
    "    # save old names to garbage file\n",
    "    oldname_file = GARBAGE_DIR / \"old_column_names.csv\"\n",
    "    pd.DataFrame({'old_name': old_columns}).to_csv(oldname_file, index=False)\n",
    "    print(f\"✓ Old column names written to {oldname_file}\")\n",
    "\n",
    "    df_cleaned.columns = EXPECTED_COLS\n",
    "    print(\"Renamed cleaned dataframe columns to expected names:\")\n",
    "    print(df_cleaned.columns.tolist())\n",
    "else:\n",
    "    print(f\"⚠️  Column count ({len(old_columns)}) does not match expected ({len(EXPECTED_COLS)}); skipping rename\")\n",
    "    print(\"Current columns:\", old_columns)\n",
    "\n",
    "# Log column renaming\n",
    "logging.info(f\"Old column names saved: {oldname_file if 'oldname_file' in locals() else 'none'}\")\n",
    "logging.info(f\"Final column names: {df_cleaned.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673cdff9",
   "metadata": {},
   "source": [
    "### Step 6: Validate Kept Columns for Whitespace\n",
    "Inspect the cleaned dataset to ensure no leading/trailing spaces remain in the retained columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8bd16fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WHITESPACE CHECK ON CLEANED DATA:\n",
      "Columns with whitespace issues:\n",
      " - Name: 89 cells\n",
      "\n",
      "Sample rows with issues (up to 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tia Brathwaite</td>\n",
       "      <td>Tia.Brathwaite@mail.kkhair.net</td>\n",
       "      <td>3c681d06bd2aa399</td>\n",
       "      <td>1984/04/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sofía Greenidge</td>\n",
       "      <td>Sofa.Greenidge-387@@kkhairemporium.com</td>\n",
       "      <td>b98bfe3fa6bad1__</td>\n",
       "      <td>2006/12/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Khadija De la Cruz</td>\n",
       "      <td>Khadija.Cruz-711@kandk-hair.co</td>\n",
       "      <td>44205eb64de62343</td>\n",
       "      <td>1989/06/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Jéssica Jean-Baptiste</td>\n",
       "      <td>Jssica.Jean-Baptiste@@loyalty.kkhair.com</td>\n",
       "      <td>c9367df148217dbe</td>\n",
       "      <td>1962/08/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Kirsten Brathwaite St. Clair</td>\n",
       "      <td>Kirsten.Clair.600@KKHAIREMPORIUM.COM</td>\n",
       "      <td>49b04310c296b6d4</td>\n",
       "      <td>1974/10/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Latoya Núñez</td>\n",
       "      <td>Latoya.Nez@#.kkhairemporium.com</td>\n",
       "      <td>751b70528cbcc602</td>\n",
       "      <td>2004/4/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Anaïs Alleyne</td>\n",
       "      <td>Anas.Alleyne@loyalty.kkhair.com</td>\n",
       "      <td>f6a041053984e072</td>\n",
       "      <td>1999/04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>José  Núñez</td>\n",
       "      <td>Jos.Nez@mail.kkhair.net</td>\n",
       "      <td>7dcacccd65f46cbd</td>\n",
       "      <td>1966-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jermaine Campbell</td>\n",
       "      <td>Jermaine.Campbell@MAIL.KKHAIR.NET</td>\n",
       "      <td>d7515f29bd07633b</td>\n",
       "      <td>2003/06/03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Latoya García</td>\n",
       "      <td>Latoya.Garca@kandk-hair.co</td>\n",
       "      <td>0d64b9720f95e0ee</td>\n",
       "      <td>1991/05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name                             Email Address  \\\n",
       "6                  Tia Brathwaite              Tia.Brathwaite@mail.kkhair.net   \n",
       "35                Sofía Greenidge      Sofa.Greenidge-387@@kkhairemporium.com   \n",
       "44             Khadija De la Cruz              Khadija.Cruz-711@kandk-hair.co   \n",
       "47          Jéssica Jean-Baptiste    Jssica.Jean-Baptiste@@loyalty.kkhair.com   \n",
       "64   Kirsten Brathwaite St. Clair        Kirsten.Clair.600@KKHAIREMPORIUM.COM   \n",
       "69                   Latoya Núñez             Latoya.Nez@#.kkhairemporium.com   \n",
       "74                  Anaïs Alleyne             Anas.Alleyne@loyalty.kkhair.com   \n",
       "89                  José  Núñez                       Jos.Nez@mail.kkhair.net   \n",
       "95              Jermaine Campbell           Jermaine.Campbell@MAIL.KKHAIR.NET   \n",
       "97                  Latoya García                  Latoya.Garca@kandk-hair.co   \n",
       "\n",
       "                Salt Date of Birth  \n",
       "6   3c681d06bd2aa399    1984/04/06  \n",
       "35  b98bfe3fa6bad1__    2006/12/16  \n",
       "44  44205eb64de62343   1989/06/14   \n",
       "47  c9367df148217dbe    1962/08/14  \n",
       "64  49b04310c296b6d4    1974/10/22  \n",
       "69  751b70528cbcc602     2004/4/22  \n",
       "74  f6a041053984e072       1999/04  \n",
       "89  7dcacccd65f46cbd    1966-04-06  \n",
       "95  d7515f29bd07633b    2003/06/03  \n",
       "97  0d64b9720f95e0ee       1991/05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for leading/trailing whitespace in cleaned data columns\n",
    "print(\"\\nWHITESPACE CHECK ON CLEANED DATA:\")\n",
    "problem_cols = {}\n",
    "for col in df_cleaned.columns:  # iterate actual dataframe columns\n",
    "    if df_cleaned[col].dtype == 'object':\n",
    "        count = df_cleaned[col].astype(str).str.match(r\"^\\s|\\s$\").sum()\n",
    "        if count > 0:\n",
    "            problem_cols[col] = count\n",
    "\n",
    "if problem_cols:\n",
    "    print(\"Columns with whitespace issues:\")\n",
    "    for col, cnt in problem_cols.items():\n",
    "        print(f\" - {col}: {cnt} cells\")\n",
    "    # show a snippet of up to 10 rows\n",
    "    print(\"\\nSample rows with issues (up to 10):\")\n",
    "    mask = False\n",
    "    for col in problem_cols:\n",
    "        mask |= df_cleaned[col].astype(str).str.match(r\"^\\s|\\s$\")\n",
    "    display(df_cleaned[mask].head(10))\n",
    "else:\n",
    "    print(\"✓ No leading/trailing spaces detected in cleaned columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3bbac",
   "metadata": {},
   "source": [
    "# Duplicate row analysis on cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a693cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DUPLICATE ROWS: 60 total (6.00% of dataset)\n",
      "\n",
      "Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Khadija Baptiste</td>\n",
       "      <td>KHADIJA.BAPTISTE@loyalty.kkhair.com</td>\n",
       "      <td>b4d419b1b673bd47</td>\n",
       "      <td>1970/11/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Renée Holder</td>\n",
       "      <td>RENE.HOLDER@loyalty.kkhair.com</td>\n",
       "      <td>c752344fd8be7e12</td>\n",
       "      <td>1958-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Tyrone Forde</td>\n",
       "      <td>Tyrone.Forde@kkhairemporium.com</td>\n",
       "      <td>2b7fdd13888ad8__</td>\n",
       "      <td>1998/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Latoya Brathwaite</td>\n",
       "      <td>Latoya.Brathwaite@mail.kkhair.net</td>\n",
       "      <td>cc18cabdda4b86f9</td>\n",
       "      <td>1995/05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Anaïs Hernández</td>\n",
       "      <td>Anas.Hernndez@loyalty.kkhair.com</td>\n",
       "      <td>7f0348598d5d65b3</td>\n",
       "      <td>1980/11/27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Keisha Ramdeen</td>\n",
       "      <td>Keisha.Ramdeen@kkhairemporium.com</td>\n",
       "      <td>7d8949a229bee1e2</td>\n",
       "      <td>1971/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Anaïs Charles</td>\n",
       "      <td>Anas.Charles.635@kandk-hair.co</td>\n",
       "      <td>8cd419af4f38e48c</td>\n",
       "      <td>1963/01/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Kareem Alleyne</td>\n",
       "      <td>Kareem.Alleyne@kandk-hair.co</td>\n",
       "      <td>4f98f1c6d2a4fca9</td>\n",
       "      <td>1968-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Noël Best</td>\n",
       "      <td>Nol.Best@kkhairemporium.com</td>\n",
       "      <td>a57a3d675d8f2112</td>\n",
       "      <td>1996/09/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Sade Joseph</td>\n",
       "      <td>Sade.Joseph@loyalty.kkhair.com</td>\n",
       "      <td>9cbd92a9d6a3eaf6</td>\n",
       "      <td>1961/02/05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name                        Email Address  \\\n",
       "5        Khadija Baptiste  KHADIJA.BAPTISTE@loyalty.kkhair.com   \n",
       "190          Renée Holder       RENE.HOLDER@loyalty.kkhair.com   \n",
       "206          Tyrone Forde      Tyrone.Forde@kkhairemporium.com   \n",
       "218   Latoya Brathwaite      Latoya.Brathwaite@mail.kkhair.net   \n",
       "243       Anaïs Hernández     Anas.Hernndez@loyalty.kkhair.com   \n",
       "263        Keisha Ramdeen    Keisha.Ramdeen@kkhairemporium.com   \n",
       "285         Anaïs Charles       Anas.Charles.635@kandk-hair.co   \n",
       "465        Kareem Alleyne         Kareem.Alleyne@kandk-hair.co   \n",
       "503             Noël Best          Nol.Best@kkhairemporium.com   \n",
       "576           Sade Joseph       Sade.Joseph@loyalty.kkhair.com   \n",
       "\n",
       "                 Salt Date of Birth  \n",
       "5    b4d419b1b673bd47    1970/11/19  \n",
       "190  c752344fd8be7e12    1958-06-08  \n",
       "206  2b7fdd13888ad8__       1998/07  \n",
       "218  cc18cabdda4b86f9    1995/05/12  \n",
       "243  7f0348598d5d65b3    1980/11/27  \n",
       "263  7d8949a229bee1e2       1971/01  \n",
       "285  8cd419af4f38e48c    1963/01/13  \n",
       "465  4f98f1c6d2a4fca9    1968-12-06  \n",
       "503  a57a3d675d8f2112    1996/09/23  \n",
       "576  9cbd92a9d6a3eaf6    1961/02/05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exported duplicates to \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_processed\\duplicate_rows.csv\n",
      "✓ Dropped duplicate rows from cleaned data and wrote to \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_garbage\\duplicate_rows.csv\n",
      "\n",
      "DUPLICATE VALUES WITHIN COLUMNS:\n",
      " - Name: 238 duplicate entries\n",
      " - Email Address: 26 duplicate entries\n",
      " - Salt: 39 duplicate entries\n",
      " - Date of Birth: 53 duplicate entries\n",
      "\n",
      "Duplicate check complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "duplicates = df_cleaned.duplicated(keep=False)\n",
    "num_dup = duplicates.sum()\n",
    "print(f\"\\nDUPLICATE ROWS: {num_dup} total ({(num_dup/len(df_cleaned)*100):.2f}% of dataset)\")\n",
    "\n",
    "dup_file = None\n",
    "if num_dup > 0:\n",
    "    dup_rows = df_cleaned[duplicates]\n",
    "    print(\"\\nSample duplicates:\")\n",
    "    display(dup_rows.head(10))\n",
    "    # save duplicates to processed folder\n",
    "    dup_file = PROCESSED_DIR / \"duplicate_rows.csv\"\n",
    "    dup_rows.to_csv(dup_file, index=False)\n",
    "    print(f\"✓ Exported duplicates to {dup_file}\")\n",
    "\n",
    "    # also move duplicates to garbage and remove them from df_cleaned\n",
    "    garbage_dup_file = GARBAGE_DIR / \"duplicate_rows.csv\"\n",
    "    dup_rows.to_csv(garbage_dup_file, index=False)\n",
    "    df_cleaned = df_cleaned.drop(dup_rows.index)\n",
    "    print(f\"✓ Dropped duplicate rows from cleaned data and wrote to {garbage_dup_file}\")\n",
    "else:\n",
    "    print(\"✓ No duplicate rows found in cleaned data.\")\n",
    "\n",
    "# check for duplicate values within each column\n",
    "print(\"\\nDUPLICATE VALUES WITHIN COLUMNS:\")\n",
    "for col in df_cleaned.columns:\n",
    "    dup_vals = df_cleaned[col][df_cleaned[col].duplicated()]\n",
    "    if not dup_vals.empty:\n",
    "        print(f\" - {col}: {len(dup_vals)} duplicate entries\")\n",
    "\n",
    "print(\"\\nDuplicate check complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27df8c6",
   "metadata": {},
   "source": [
    "# Standardize Date of Birth format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cf926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date of Birth column standardized to YYYY/MM/DD format. Sample:\n",
      "0    1958/11/24\n",
      "1    1996/12/28\n",
      "2           NaN\n",
      "3    1974/03/06\n",
      "4    2000/05/20\n",
      "Name: Date of Birth, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if \"Date of Birth\" in df_cleaned.columns:\n",
    "    # parse as datetime if not already\n",
    "    df_cleaned[\"Date of Birth\"] = pd.to_datetime(df_cleaned[\"Date of Birth\"], errors='coerce')\n",
    "    # format YYYY/MM/DD\n",
    "    df_cleaned[\"Date of Birth\"] = df_cleaned[\"Date of Birth\"].dt.strftime(\"%Y/%m/%d\")\n",
    "    print(\"Date of Birth column standardized to YYYY/MM/DD format. Sample:\")\n",
    "    print(df_cleaned[\"Date of Birth\"].head())\n",
    "else:\n",
    "    print(\"Date of Birth column not found in dataframe.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949cc72d",
   "metadata": {},
   "source": [
    "# Remove rows with invalid/missing date of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b15124ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INVALID DATE OF BIRTH RECORDS: 314 rows\n",
      "\n",
      "Sample invalid records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohan Williams</td>\n",
       "      <td>Rohan.Williams@kkhairemporium.com</td>\n",
       "      <td>f244f58d669cbee3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tyrone Campbell</td>\n",
       "      <td>Tyrone.Campbell@loyalty.kkhair.com</td>\n",
       "      <td>d7f78df0cac5e40c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kareem Campbell</td>\n",
       "      <td>KAREEM.CAMPBELL@KANDK-HAIR.CO</td>\n",
       "      <td>359309cc6273931b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>José Baptiste</td>\n",
       "      <td>JOS.BAPTISTE@mail.kkhair.net</td>\n",
       "      <td>bfe16849ef307590</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sade  Núñez</td>\n",
       "      <td>Sade.Nez@mail.kkhair.net</td>\n",
       "      <td>fcc4f14a3e3e04d4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Noël De la Cruz</td>\n",
       "      <td>Nol.Cruz-615@loyalty.kkhair.com</td>\n",
       "      <td>d080589ab054c240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dwayne De la Cruz</td>\n",
       "      <td>DWAYNE.CRUZ-614@kkhairemporium.com</td>\n",
       "      <td>c7b2c1d0e2adcd93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Marlon St. Clair</td>\n",
       "      <td>Marlon.Clair-940@loyalty.kkhair.com</td>\n",
       "      <td>29ca42db0b956af6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Marlon Charles</td>\n",
       "      <td>Marlon.Charles@kandk-hair.co</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Khadija Best</td>\n",
       "      <td>Khadija.Bestkkhairemporium.com</td>\n",
       "      <td>a7b92868492545a1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                        Email Address              Salt  \\\n",
       "2      Rohan Williams    Rohan.Williams@kkhairemporium.com  f244f58d669cbee3   \n",
       "8     Tyrone Campbell   Tyrone.Campbell@loyalty.kkhair.com  d7f78df0cac5e40c   \n",
       "9     Kareem Campbell        KAREEM.CAMPBELL@KANDK-HAIR.CO  359309cc6273931b   \n",
       "13      José Baptiste         JOS.BAPTISTE@mail.kkhair.net  bfe16849ef307590   \n",
       "14        Sade  Núñez             Sade.Nez@mail.kkhair.net  fcc4f14a3e3e04d4   \n",
       "19    Noël De la Cruz      Nol.Cruz-615@loyalty.kkhair.com  d080589ab054c240   \n",
       "20  Dwayne De la Cruz   DWAYNE.CRUZ-614@kkhairemporium.com  c7b2c1d0e2adcd93   \n",
       "22   Marlon St. Clair  Marlon.Clair-940@loyalty.kkhair.com  29ca42db0b956af6   \n",
       "23     Marlon Charles         Marlon.Charles@kandk-hair.co               NaN   \n",
       "27       Khadija Best       Khadija.Bestkkhairemporium.com  a7b92868492545a1   \n",
       "\n",
       "   Date of Birth  \n",
       "2            NaN  \n",
       "8            NaN  \n",
       "9            NaN  \n",
       "13           NaN  \n",
       "14           NaN  \n",
       "19           NaN  \n",
       "20           NaN  \n",
       "22           NaN  \n",
       "23           NaN  \n",
       "27           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Invalid records saved to \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_garbage\\invalid_dates.csv\n",
      "✓ Removed 314 rows with invalid/missing dates\n",
      "  Cleaned data now has 626 rows\n"
     ]
    }
   ],
   "source": [
    "if \"Date of Birth\" in df_cleaned.columns:\n",
    "    # identify invalid rows: NaN, empty, or not matching YYYY/MM/DD format\n",
    "    invalid_mask = (df_cleaned[\"Date of Birth\"].isna()) | \\\n",
    "                   (df_cleaned[\"Date of Birth\"].astype(str).str.strip() == '') | \\\n",
    "                   (~df_cleaned[\"Date of Birth\"].astype(str).str.match(r'^\\d{4}/\\d{2}/\\d{2}$'))\n",
    "    \n",
    "    num_invalid = invalid_mask.sum()\n",
    "    print(f\"\\nINVALID DATE OF BIRTH RECORDS: {num_invalid} rows\")\n",
    "    \n",
    "    if num_invalid > 0:\n",
    "        invalid_rows = df_cleaned[invalid_mask]\n",
    "        print(\"\\nSample invalid records:\")\n",
    "        display(invalid_rows.head(10))\n",
    "        \n",
    "        # save to garbage folder\n",
    "        invalid_dob_file = GARBAGE_DIR / \"invalid_dates.csv\"\n",
    "        invalid_rows.to_csv(invalid_dob_file, index=False)\n",
    "        print(f\"✓ Invalid records saved to {invalid_dob_file}\")\n",
    "        \n",
    "        # remove from df_cleaned\n",
    "        df_cleaned = df_cleaned[~invalid_mask]\n",
    "        print(f\"✓ Removed {num_invalid} rows with invalid/missing dates\")\n",
    "        print(f\"  Cleaned data now has {len(df_cleaned)} rows\")\n",
    "        \n",
    "        logging.info(f\"Removed {num_invalid} rows with invalid/missing Date of Birth\")\n",
    "        logging.info(f\"Cleaned data rows after removal: {len(df_cleaned)}\")\n",
    "    else:\n",
    "        print(\"✓ All Date of Birth records are valid.\")\n",
    "else:\n",
    "    print(\"Date of Birth column not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7732b",
   "metadata": {},
   "source": [
    "# Save final cleaned data with correct column names\n",
    "\n",
    "# ensure column names still correct before final save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bfa57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INVALID EMAIL RECORDS: 53 rows\n",
      "\n",
      "Sample rows with invalid email formats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tanesha García</td>\n",
       "      <td>Tanesha.Garca@@mail.kkhair.net</td>\n",
       "      <td>a5c9af9f0ba3d90f</td>\n",
       "      <td>2006/11/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Kofi Morris</td>\n",
       "      <td>Kofi.Morris@ kkhairemporium.com</td>\n",
       "      <td>47d9815df1bcadd4</td>\n",
       "      <td>1971/07/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sofía Greenidge</td>\n",
       "      <td>Sofa.Greenidge-387@@kkhairemporium.com</td>\n",
       "      <td>b98bfe3fa6bad1__</td>\n",
       "      <td>2006/12/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Jéssica Jean-Baptiste</td>\n",
       "      <td>Jssica.Jean-Baptiste@@loyalty.kkhair.com</td>\n",
       "      <td>c9367df148217dbe</td>\n",
       "      <td>1962/08/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Sofía De la Cruz</td>\n",
       "      <td>Sofa.Cruz@</td>\n",
       "      <td>9e3f12f63c9d1446</td>\n",
       "      <td>2006/01/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Mikaël Thompson</td>\n",
       "      <td>Mikal.Thompson@</td>\n",
       "      <td>afeeb9f352846822</td>\n",
       "      <td>2000/07/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Noël Pérez</td>\n",
       "      <td>Nol.Prez_184@</td>\n",
       "      <td>bcfe11a3885ccb28</td>\n",
       "      <td>1974/12/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Rohan Campbell-Pérez</td>\n",
       "      <td>Rohan.Campbell-Prez@</td>\n",
       "      <td>13ee17c1c169ec99</td>\n",
       "      <td>1992/11/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Tanesha  Best</td>\n",
       "      <td>TANESHA.BEST-722loyalty.kkhair.com</td>\n",
       "      <td>27f291a0fefadb99</td>\n",
       "      <td>1982/04/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Anaïs Joseph</td>\n",
       "      <td>Anas.Josephloyalty.kkhair.com</td>\n",
       "      <td>595545731a4e8b56</td>\n",
       "      <td>1958/02/10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name                             Email Address  \\\n",
       "29            Tanesha García            Tanesha.Garca@@mail.kkhair.net   \n",
       "34               Kofi Morris           Kofi.Morris@ kkhairemporium.com   \n",
       "35         Sofía Greenidge      Sofa.Greenidge-387@@kkhairemporium.com   \n",
       "47   Jéssica Jean-Baptiste    Jssica.Jean-Baptiste@@loyalty.kkhair.com   \n",
       "56          Sofía De la Cruz                                Sofa.Cruz@   \n",
       "65           Mikaël Thompson                           Mikal.Thompson@   \n",
       "66                Noël Pérez                             Nol.Prez_184@   \n",
       "82      Rohan Campbell-Pérez                      Rohan.Campbell-Prez@   \n",
       "90             Tanesha  Best        TANESHA.BEST-722loyalty.kkhair.com   \n",
       "99              Anaïs Joseph             Anas.Josephloyalty.kkhair.com   \n",
       "\n",
       "                Salt Date of Birth  \n",
       "29  a5c9af9f0ba3d90f    2006/11/24  \n",
       "34  47d9815df1bcadd4    1971/07/01  \n",
       "35  b98bfe3fa6bad1__    2006/12/16  \n",
       "47  c9367df148217dbe    1962/08/14  \n",
       "56  9e3f12f63c9d1446    2006/01/31  \n",
       "65  afeeb9f352846822    2000/07/02  \n",
       "66  bcfe11a3885ccb28    1974/12/30  \n",
       "82  13ee17c1c169ec99    1992/11/25  \n",
       "90  27f291a0fefadb99    1982/04/12  \n",
       "99  595545731a4e8b56    1958/02/10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Invalid email rows saved to \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_garbage\\invalid_emails.csv\n",
      "✓ Removed 53 rows with invalid emails\n"
     ]
    }
   ],
   "source": [
    "# Validate email addresses if present\n",
    "if \"Email Address\" in df_cleaned.columns:\n",
    "    # simple regex for basic email validation\n",
    "    email_pattern = r'^[^@\\s]+@[^@\\s]+\\.[^@\\s]+$'\n",
    "    invalid_email_mask = ~df_cleaned[\"Email Address\"].astype(str).str.match(email_pattern)\n",
    "\n",
    "    num_invalid_emails = invalid_email_mask.sum()\n",
    "    print(f\"\\nINVALID EMAIL RECORDS: {num_invalid_emails} rows\")\n",
    "\n",
    "    if num_invalid_emails > 0:\n",
    "        invalid_email_rows = df_cleaned[invalid_email_mask]\n",
    "        print(\"\\nSample rows with invalid email formats:\")\n",
    "        display(invalid_email_rows.head(10))\n",
    "\n",
    "        # save invalid emails to garbage folder\n",
    "        email_garbage_file = GARBAGE_DIR / \"invalid_emails.csv\"\n",
    "        invalid_email_rows.to_csv(email_garbage_file, index=False)\n",
    "        print(f\"✓ Invalid email rows saved to {email_garbage_file}\")\n",
    "\n",
    "        # remove them from the cleaned dataframe\n",
    "        df_cleaned = df_cleaned[~invalid_email_mask]\n",
    "        print(f\"✓ Removed {num_invalid_emails} rows with invalid emails\")\n",
    "    else:\n",
    "        print(\"✓ All email addresses appear valid.\")\n",
    "else:\n",
    "    print(\"Email Address column not found in dataframe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f277594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL CLEANED DATA SUMMARY:\n",
      "Shape: 573 rows × 4 columns\n",
      "Columns: ['Name', 'Email Address', 'Salt', 'Date of Birth']\n",
      "\n",
      "First 5 rows of final cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shanice O'Connor</td>\n",
       "      <td>Shanice.OConnor@KKHAIREMPORIUM.COM</td>\n",
       "      <td>e805da846a32c3bb</td>\n",
       "      <td>1958/11/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Renée Lewis</td>\n",
       "      <td>RENE.LEWIS@kandk-hair.co</td>\n",
       "      <td>78dcb74f21345d2c</td>\n",
       "      <td>1996/12/28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devon Baptiste</td>\n",
       "      <td>Devon.Baptiste.442@loyalty.kkhair.com</td>\n",
       "      <td>e4d58e72e310275d</td>\n",
       "      <td>1974/03/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Devon Baptiste</td>\n",
       "      <td>Devon.Baptiste@KKHAIREMPORIUM.COM</td>\n",
       "      <td>a86a78c49ea20e32</td>\n",
       "      <td>2000/05/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tia Brathwaite</td>\n",
       "      <td>Tia.Brathwaite@mail.kkhair.net</td>\n",
       "      <td>3c681d06bd2aa399</td>\n",
       "      <td>1984/04/06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                          Email Address              Salt  \\\n",
       "0   Shanice O'Connor     Shanice.OConnor@KKHAIREMPORIUM.COM  e805da846a32c3bb   \n",
       "1        Renée Lewis               RENE.LEWIS@kandk-hair.co  78dcb74f21345d2c   \n",
       "3     Devon Baptiste  Devon.Baptiste.442@loyalty.kkhair.com  e4d58e72e310275d   \n",
       "4     Devon Baptiste      Devon.Baptiste@KKHAIREMPORIUM.COM  a86a78c49ea20e32   \n",
       "6   Tia Brathwaite           Tia.Brathwaite@mail.kkhair.net  3c681d06bd2aa399   \n",
       "\n",
       "  Date of Birth  \n",
       "0    1958/11/24  \n",
       "1    1996/12/28  \n",
       "3    1974/03/06  \n",
       "4    2000/05/20  \n",
       "6    1984/04/06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Final cleaned data saved to \\\\bca-org-00\\Users Folder\\jalleyne\\Desktop\\Protexxa\\data_cleaning_scripts\\K & K Hair Emporium_dataset\\K & K Hair Emporium_dataset\\k & k hair emporium_raw\\k & k hair emporium_ingested\\df_cleaned_final.csv\n"
     ]
    }
   ],
   "source": [
    "EXPECTED_COLS = [\"Name\", \"Email Address\", \"Salt\", \"Date of Birth\"]\n",
    "if list(df_cleaned.columns) != EXPECTED_COLS and len(df_cleaned.columns) == len(EXPECTED_COLS):\n",
    "    df_cleaned.columns = EXPECTED_COLS\n",
    "    print(\"Reapplied expected column names before final save.\")\n",
    "\n",
    "print(\"\\nFINAL CLEANED DATA SUMMARY:\")\n",
    "print(f\"Shape: {df_cleaned.shape[0]} rows × {df_cleaned.shape[1]} columns\")\n",
    "print(f\"Columns: {df_cleaned.columns.tolist()}\")\n",
    "print(\"\\nFirst 5 rows of final cleaned data:\")\n",
    "display(df_cleaned.head())\n",
    "\n",
    "# Save the final cleaned data with proper column names\n",
    "final_cleaned_file = INGESTED_DIR / \"df_cleaned_final.csv\"\n",
    "df_cleaned.to_csv(final_cleaned_file, index=False)\n",
    "print(f\"\\n✓ Final cleaned data saved to {final_cleaned_file}\")\n",
    "\n",
    "logging.info(f\"Final cleaned data shape: {df_cleaned.shape}\")\n",
    "logging.info(f\"Final column names: {df_cleaned.columns.tolist()}\")\n",
    "logging.info(f\"Final cleaned data saved to {final_cleaned_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a503074",
   "metadata": {},
   "source": [
    "# verify total row counts to ensure no data lost and everything accounted for\n",
    "\n",
    "# gather counts by inspecting saved garbage/processed CSV files on disk\n",
    "\n",
    "# only count each removal category once (processed duplicate file is authoritative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7375d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATAQUANTITY CHECK ===\n",
      "Original raw data rows: 1000\n",
      "Final cleaned data rows: 573\n",
      "Rows removed during cleaning: 427\n",
      "Data loss occurred? True\n",
      "\n",
      "Counts from exported files:\n",
      " - duplicate_rows: 60 rows\n",
      " - invalid_dates: 314 rows\n",
      " - invalid_emails: 53 rows\n",
      "Sum of exported rows: 427\n",
      "All rows accounted for? True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DATAQUANTITY CHECK ===\")\n",
    "print(f\"Original raw data rows: {len(df_raw)}\")\n",
    "print(f\"Final cleaned data rows: {len(df_cleaned)}\")\n",
    "removed = len(df_raw) - len(df_cleaned)\n",
    "print(f\"Rows removed during cleaning: {removed}\")\n",
    "\n",
    "data_loss = removed > 0\n",
    "print(f\"Data loss occurred? {data_loss}\")\n",
    "\n",
    "\n",
    "file_counts = {}\n",
    "\n",
    "paths = {\n",
    "    'duplicate_rows': PROCESSED_DIR / 'duplicate_rows.csv',\n",
    "    'invalid_dates': GARBAGE_DIR / 'invalid_dates.csv',\n",
    "    'invalid_emails': GARBAGE_DIR / 'invalid_emails.csv',\n",
    "}\n",
    "for label, path in paths.items():\n",
    "    if path.exists():\n",
    "        try:\n",
    "            df_tmp = pd.read_csv(path)\n",
    "            file_counts[label] = len(df_tmp)\n",
    "        except Exception:\n",
    "            file_counts[label] = None\n",
    "\n",
    "if file_counts:\n",
    "    print(\"\\nCounts from exported files:\")\n",
    "    for k, v in file_counts.items():\n",
    "        print(f\" - {k}: {v if v is not None else 'error reading'} rows\")\n",
    "    # sum valid numeric counts\n",
    "    numeric = [v for v in file_counts.values() if isinstance(v, (int, float))]\n",
    "    total_exported = sum(numeric)\n",
    "    print(f\"Sum of exported rows: {total_exported}\")\n",
    "    accounted = (len(df_cleaned) + total_exported) == len(df_raw)\n",
    "    print(f\"All rows accounted for? {accounted}\")\n",
    "else:\n",
    "    print(\"\\nNo exported files found for counting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fadc483",
   "metadata": {},
   "source": [
    "# Post-cleaning analysis and output validation\n",
    "\n",
    "# check existence of key output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe18039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POST-CLEANING ANALYSIS ===\n",
      "Cleaned dataframe shape: (573, 4)\n",
      "Column data types:\n",
      "Name             object\n",
      "Email Address    object\n",
      "Salt             object\n",
      "Date of Birth    object\n",
      "dtype: object\n",
      "\n",
      "Missing values by column:\n",
      "Name             0\n",
      "Email Address    0\n",
      "Salt             0\n",
      "Date of Birth    0\n",
      "dtype: int64\n",
      "\n",
      "Output files status:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cleaned.csv: FOUND\n",
      "df_cleaned_final.csv: FOUND\n",
      "invalid_dates.csv: FOUND\n",
      "invalid_emails.csv: FOUND\n",
      "duplicate_rows.csv: FOUND\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== POST-CLEANING ANALYSIS ===\")\n",
    "print(f\"Cleaned dataframe shape: {df_cleaned.shape}\")\n",
    "print(\"Column data types:\")\n",
    "print(df_cleaned.dtypes)\n",
    "print(\"\\nMissing values by column:\")\n",
    "print(df_cleaned.isna().sum())\n",
    "\n",
    "\n",
    "def check_file(path):\n",
    "    exists = path.exists()\n",
    "    print(f\"{path.name}: {'FOUND' if exists else 'MISSING'}\")\n",
    "    return exists\n",
    "\n",
    "print(\"\\nOutput files status:\")\n",
    "files_to_check = [\n",
    "    INGESTED_DIR / \"df_cleaned.csv\",\n",
    "    INGESTED_DIR / \"df_cleaned_final.csv\",\n",
    "    GARBAGE_DIR / \"invalid_dates.csv\",\n",
    "    GARBAGE_DIR / \"invalid_emails.csv\",\n",
    "    PROCESSED_DIR / \"duplicate_rows.csv\",\n",
    "]\n",
    "for f in files_to_check:\n",
    "    check_file(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829e285",
   "metadata": {},
   "source": [
    "# final verification of cleaned data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3a6f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL FILE VERIFICATION ===\n",
      "Final CSV shape: (573, 4)\n",
      "Loaded file identical to in-memory df_cleaned? False\n",
      "\n",
      "Sample from final file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shanice O'Connor</td>\n",
       "      <td>Shanice.OConnor@KKHAIREMPORIUM.COM</td>\n",
       "      <td>e805da846a32c3bb</td>\n",
       "      <td>1958/11/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Renée Lewis</td>\n",
       "      <td>RENE.LEWIS@kandk-hair.co</td>\n",
       "      <td>78dcb74f21345d2c</td>\n",
       "      <td>1996/12/28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devon Baptiste</td>\n",
       "      <td>Devon.Baptiste.442@loyalty.kkhair.com</td>\n",
       "      <td>e4d58e72e310275d</td>\n",
       "      <td>1974/03/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devon Baptiste</td>\n",
       "      <td>Devon.Baptiste@KKHAIREMPORIUM.COM</td>\n",
       "      <td>a86a78c49ea20e32</td>\n",
       "      <td>2000/05/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tia Brathwaite</td>\n",
       "      <td>Tia.Brathwaite@mail.kkhair.net</td>\n",
       "      <td>3c681d06bd2aa399</td>\n",
       "      <td>1984/04/06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                          Email Address              Salt  \\\n",
       "0   Shanice O'Connor     Shanice.OConnor@KKHAIREMPORIUM.COM  e805da846a32c3bb   \n",
       "1        Renée Lewis               RENE.LEWIS@kandk-hair.co  78dcb74f21345d2c   \n",
       "2     Devon Baptiste  Devon.Baptiste.442@loyalty.kkhair.com  e4d58e72e310275d   \n",
       "3     Devon Baptiste      Devon.Baptiste@KKHAIREMPORIUM.COM  a86a78c49ea20e32   \n",
       "4   Tia Brathwaite           Tia.Brathwaite@mail.kkhair.net  3c681d06bd2aa399   \n",
       "\n",
       "  Date of Birth  \n",
       "0    1958/11/24  \n",
       "1    1996/12/28  \n",
       "2    1974/03/06  \n",
       "3    2000/05/20  \n",
       "4    1984/04/06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Any missing values?\n",
      "Name             0\n",
      "Email Address    0\n",
      "Salt             0\n",
      "Date of Birth    0\n",
      "dtype: int64\n",
      "\n",
      "Any duplicates?\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FINAL FILE VERIFICATION ===\")\n",
    "final_path = INGESTED_DIR / \"df_cleaned_final.csv\"\n",
    "if final_path.exists():\n",
    "    df_final = pd.read_csv(final_path)\n",
    "    print(f\"Final CSV shape: {df_final.shape}\")\n",
    "    same = df_final.equals(df_cleaned)\n",
    "    print(f\"Loaded file identical to in-memory df_cleaned? {same}\")\n",
    "    print(\"\\nSample from final file:\")\n",
    "    display(df_final.head())\n",
    "    # extra diagnostics\n",
    "    print(\"\\nAny missing values?\")\n",
    "    print(df_final.isna().sum())\n",
    "    print(\"\\nAny duplicates?\")\n",
    "    print(df_final.duplicated().sum())\n",
    "else:\n",
    "    print(f\"Final file not found at {final_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
